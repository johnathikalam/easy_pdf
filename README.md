# ğŸ“„ AI-Powered RAG-Based Document Chatbot with Pinecone & OpenAI  

This project is a **Flask-based web application** that enables users to **upload PDF files** and chat with their documents using **Retrieval-Augmented Generation (RAG)**. It leverages **Pinecone Vector Store** and **OpenAI's GPT model** to retrieve the most relevant document information before generating AI-powered responses.  

---

## ğŸš€ Features  

- ğŸ“¤ **Upload PDFs** and extract text  
- ğŸ” **RAG-based chatbot** for improved document-based Q&A  
- ğŸ“Š **Store document embeddings** in Pinecone for fast retrieval  
- ğŸ¤– **Retrieve and generate responses** using OpenAI GPT-4o  
- ğŸ› ï¸ **Toggle external knowledge** for more comprehensive answers  
- ğŸ§¹ **Clear stored vectors** anytime  
- ğŸ¨ **Tailwind CSS-based UI** with animations  

---

## ğŸ—ï¸ Tech Stack  

- **Frontend**: HTML, Tailwind CSS, JavaScript  
- **Backend**: Flask, Python  
- **AI Models**: OpenAI GPT-4o, OpenAI Embeddings  
- **Vector Database**: Pinecone  
- **Document Processing**: LangChain, PyPDFLoader  
- **AI Technique**: **Retrieval-Augmented Generation (RAG)**  

---
## ğŸ”§ Installation & Setup  

### **1ï¸âƒ£ Clone the Repository**  

```sh
git clone https://github.com/yourusername/ai-document-chatbot.git
cd ai-document-chatbot
```

### **2ï¸âƒ£ Create a Virtual Environment**
```sh
Copy
Edit
py -3.10 -m venv venv
source venv/bin/activate   # On macOS/Linux
venv\Scripts\activate      # On Windows
```
### **3ï¸âƒ£ Install Dependencies**
```sh

pip install -r requirements.txt
```
### **4ï¸âƒ£ Set Up Environment Variables**
Create a .env file in the project root and add:

```ini
OPENAI_API_KEY=your_openai_api_key
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_INDEX_NAME=your_pinecone_index
```
### **â–¶ï¸ Running the Application*
Start the Flask server:

```sh
python flask_app.py
```